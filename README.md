ğŸš€ Autonomous Research Intelligence Engine

AI-powered system that automatically decomposes complex strategic research questions into structured, actionable sub-questions for faster and more comprehensive analysis.

ğŸ§© Problem Statement
Problem Title

The Research That Takes a Week and Shouldnâ€™t

Problem Description

Researchers spend significant time manually breaking complex strategic questions into smaller, searchable sub-questions. This manual process is:

Inconsistent

Slow (2â€“3 hours per question)

Prone to cognitive bias

Lacking systematic decomposition frameworks

ğŸ¯ Target Users

Academic Researchers (Students, Professors, PhD Candidates)

Market Analysts (Investment Firms, Consulting Companies)

Business Strategists (Product Managers, Growth Teams)

Policy Researchers (Government Think Tanks, NGOs)

âš ï¸ Existing Gaps

âŒ No automated question decomposition tools

âŒ Manual and time-intensive workflow

âŒ Inconsistent sub-question quality

âŒ Missed research dimensions

âŒ Lack of team-wide standardization

ğŸ” Problem Understanding & Approach
Root Cause Analysis

Process Breakdown:

Complex Question 
    â†“
Manual Breakdown 
    â†“
Inconsistent Sub-questions 
    â†“
Incomplete Research
Root Causes

Human cognitive bias

No structured decomposition framework

Time constraints

Lack of automation

ğŸ’¡ Proposed Solution
Solution Overview

Transforms:

â€œWhat are the best EV strategies in India?â€

Into:

What is the current market size of EVs in India?

Who are the key competitors?

What government regulations affect EV adoption?

What infrastructure challenges exist?

What are projected growth trends?

ğŸ§  Core Idea

LLM-powered question decomposition using structured prompting via API-based inference.

âœ¨ Key Features

Input: Complex research question (string)

Output: 5â€“7 actionable sub-questions (List[str])

Zero-shot inference (no model training required)

Modular Python architecture

Integration-ready with search & scoring modules

ğŸ—ï¸ System Architecture
High-Level Flow
User 
  â†“
Backend (FastAPI)
  â†“
Planner Module
  â†“
Search Module
  â†“
Scoring Module
  â†“
Final Structured Report
Architecture Description

The system follows a modular backend design:

main.py â†’ Handles user input and orchestration

planner.py â†’ Generates structured sub-questions

search.py â†’ Retrieves relevant information

scoring.py â†’ Ranks and filters results

ğŸ–¼ï¸ Architecture Diagram

(Add system architecture diagram image here)

ğŸ—„ï¸ Database Design
Database Approach

No database used.
The system is stateless and operates in real time.

Design Rationale

No persistence required

Simplified architecture

Scalable serverless deployment compatibility

ğŸ“Š Dataset
Dataset Name

None (Zero-shot inference)

Source

LLM API

Data Type

Pre-trained large-scale language model corpus

Selection Reason

Trained on diverse research and business content

Fast inference (<1 second per query)

Strong structured output capability

ğŸ”§ Preprocessing Steps

Structured prompt engineering

Output validation

Enforcing 5â€“7 question constraint

Response formatting validation

ğŸ¤– Model Selected
Model Name

API-based LLM (e.g., Gemini 1.5 Flash)

Selection Reasoning

Low latency

Cost-effective

Reliable structured output

Suitable for real-time decomposition

ğŸ”„ Alternatives Considered
Model	Pros	Cons
GPT-4o	High reasoning quality	Expensive
Claude	Strong reasoning	Less structured output
Llama3	Open-source	Requires self-hosting
ğŸ“ Evaluation Metrics

Completeness â†’ Always 5â€“7 sub-questions

Specificity â†’ Searchable phrasing

Consistency â†’ Low output variation

Relevance â†’ Alignment with original query

ğŸ› ï¸ Technology Stack
Frontend

HTML

CSS

JavaScript

Backend

Python 3.11

FastAPI

google-generativeai

python-dotenv

ML / AI

API-based LLM

Structured Prompt Engineering

Database

None (Stateless Architecture)

Deployment

Vercel (Frontend)

Docker (Backend â€“ Planned)

ğŸ“¡ API Documentation
Endpoint
POST /generate
Input
{
  "query": "EV market strategies in India?"
}
Output
{
  "subquestions": [
    "What is the current market size of EVs in India?",
    "Who are the major competitors?",
    "What regulatory policies affect EV adoption?",
    "What infrastructure challenges exist?",
    "What are projected growth trends?"
  ]
}

API tested using Thunder Client / Postman

(Add Postman screenshots here)

ğŸ§± Module-wise Development & Deliverables
âœ… Checkpoint 1: Research & Planning

Problem definition

Architecture design

âœ… Checkpoint 2: Backend Development

modules/planner.py

â³ Checkpoint 3: Frontend Development

Minimal UI integration

â˜‘ï¸ Checkpoint 4: Model Training (Skipped)

Zero-shot LLM used

âœ… Checkpoint 5: Model Integration

Planner integrated with API

â³ Checkpoint 6: Deployment

Docker setup (planned)

ğŸ”„ End-to-End Workflow

User enters research question

Planner generates 5â€“7 sub-questions

Search module retrieves information

Scoring module ranks quality

Structured research output delivered

ğŸ¥ Demo & Repository

Run Locally:

python main.py

GitHub Repository:
https://github.com/TheGreatPratyush/Research_analyser-

ğŸ† Hackathon Deliverables Summary

âœ… AI Planner Module

âœ… Structured Output System

âœ… Modular Backend Architecture

â³ Search & Scoring Integration

â³ UI Enhancement

ğŸ‘¥ Team Roles & Responsibilities
Member	Role	Responsibilities
Shanmukha Sai Chakali	Planner Module	modules/planner.py
Vishal Kumar Gowda	Search Module	modules/search.py
Pratyush Gupta	Scoring & Integration	modules/scoring.py
ğŸ”® Future Scope & Scalability
Short-Term

Sub-question relevance scoring

Multi-language support

Query caching

Long-Term

Custom fine-tuned research LLM

Academic database integration

Enterprise SaaS deployment

âš ï¸ Known Limitations

API dependency

English-only support

No offline mode

No persistent storage

ğŸŒ Impact

Reduces research planning time

Improves research completeness

Standardizes decomposition across teams

Enables scalable autonomous research pipelines
