ğŸš€ Autonomous Research Intelligence Engine

AI-powered system that automatically decomposes complex strategic research questions into structured, actionable sub-questions for faster and more comprehensive analysis.

ğŸ§© Problem Statement
ğŸ“Œ The Research That Takes a Week â€” and Shouldnâ€™t

Researchers spend significant time manually breaking complex strategic questions into smaller, searchable sub-questions.

This process is:

âŒ Inconsistent

âŒ Slow (2â€“3 hours per question)

âŒ Prone to cognitive bias

âŒ Lacking structured decomposition frameworks

Result â†’ Incomplete or inefficient research.

ğŸ¯ Target Users

Academic Researchers (Students, Professors, PhD Candidates)

Market Analysts (Investment Firms, Consulting Firms)

Business Strategists (Product Managers, Growth Teams)

Policy Researchers (Think Tanks, NGOs, Government Bodies)

âš ï¸ Existing Gaps

âŒ No automated question decomposition tools

âŒ Manual and time-intensive workflow

âŒ Inconsistent sub-question quality

âŒ Missed research dimensions

âŒ No team-wide standardization

ğŸ’¡ Proposed Solution
ğŸ” Example

Input:

â€œWhat are the best EV strategies in India?â€

Output:

What is the current EV market size in India?

Who are the key competitors?

What government regulations affect EV adoption?

What infrastructure challenges exist?

What are projected growth trends?

ğŸ§  Core Idea

LLM-powered question decomposition using structured prompt engineering via API-based inference.

Zero-shot (no training required)

Structured output enforcement

Fast real-time response (< 1 sec)

âœ¨ Key Features

Input: Complex research question (string)

Output: 5â€“7 structured sub-questions (List[str])

Zero-shot LLM inference

Modular backend architecture

Integration-ready with search & scoring modules

Stateless and scalable design

ğŸ—ï¸ System Architecture
High-Level Flow
User
  â†“
FastAPI Backend
  â†“
Planner Module
  â†“
Search Module
  â†“
Scoring Module
  â†“
Structured Research Report
Module Breakdown
File	Responsibility
main.py	API routing & orchestration
modules/planner.py	Generates structured sub-questions
modules/search.py	Retrieves relevant information
modules/scoring.py	Ranks and filters results
ğŸ—„ï¸ Database Design

No database used.

Stateless system

Real-time inference

Serverless-compatible

Simplified architecture

ğŸ¤– Model Selection

Model Used: API-based LLM (e.g., Gemini 1.5 Flash)

Why?

Low latency

Cost-effective

Reliable structured output

Suitable for real-time inference

ğŸ”„ Alternatives Considered
Model	Pros	Cons
GPT-4o	High reasoning quality	Expensive
Claude	Strong reasoning	Less structured output
Llama 3	Open-source	Requires self-hosting
ğŸ“ Evaluation Metrics

Completeness â†’ Always 5â€“7 sub-questions

Specificity â†’ Search-friendly phrasing

Consistency â†’ Low output variation

Relevance â†’ Strong alignment with original query

ğŸ› ï¸ Technology Stack
Frontend

HTML

CSS

JavaScript

Backend

Python 3.11

FastAPI

google-generativeai

python-dotenv

AI

API-based LLM

Structured Prompt Engineering

Deployment

Vercel (Frontend)

Docker (Backend â€“ Planned)

ğŸ“¡ API Documentation
Endpoint
POST /generate
Request
{
  "query": "EV market strategies in India?"
}
Response
{
  "subquestions": [
    "What is the current market size of EVs in India?",
    "Who are the major competitors?",
    "What regulatory policies affect EV adoption?",
    "What infrastructure challenges exist?",
    "What are projected growth trends?"
  ]
}

Tested using Postman / Thunder Client.

ğŸ”„ End-to-End Workflow

User enters research question

Planner generates 5â€“7 sub-questions

Search module retrieves relevant data

Scoring module ranks results

Structured research output is delivered

ğŸ§± Development Progress

âœ… Research & Architecture Planning

âœ… Planner Module

â³ Search Module Integration

â³ Scoring Module Integration

â³ Frontend Enhancement

â³ Docker Deployment

ğŸ‘¥ Team Roles
Member	Role	Responsibility
Shanmukha Sai Chakali	Planner	modules/planner.py
Vishal Kumar Gowda	Search	modules/search.py
Pratyush Gupta	Scoring & Integration	modules/scoring.py
ğŸ”® Future Scope
Short-Term

Sub-question relevance scoring

Multi-language support

Query caching

Long-Term

Fine-tuned research LLM

Academic database integration

Enterprise SaaS deployment

âš ï¸ Known Limitations

API dependency

English-only support

No offline mode

No persistent storage

ğŸŒ Impact

Reduces research planning time

Improves completeness of analysis

Standardizes research decomposition

Enables scalable autonomous research pipelines

â–¶ï¸ Run Locally
git clone https://github.com/TheGreatPratyush/Research_analyser-
cd Research_analyser-
pip install -r requirements.txt
python main.py
ğŸ¥ Repository

GitHub:
https://github.com/TheGreatPratyush/Research_analyser-

Standardizes decomposition across teams

Enables scalable autonomous research pipelines
